<Identificação de níveis de fadiga>
	
	Um dos objetivos principais a alcançar consiste no treino e teste de uma rede neuronal artificial, tornando-a capaz de estimar o nível de fadiga partindo de input que consiste nas diversas variáveis biométricas fornecidas. Assim, é possível em R, através da plataforma "R Studio" e da biblioteca "neuralnet", criar uma rede neuronal, fornecer-lhe input e testar diferentes configurações de forma a comparar os resultados de cada uma. Neste sentido, é feita a análise do impacto que os diferentes componentes e variantes que constituem o treino de uma rede neuronal possuem sobre o resultado final.

	<Treino da rede>

		<Algoritmos>

			Existem diversos algoritmos que definem a forma de aprendizagem de uma rede neuronal, isto é, a forma como os seus diferentes nodos interagem e como variam os pesos destes. Estes algoritmos possuem um impacto no resultado final e consistem nas seguintes variantes:


			- rprop+ e rprop- -> Algoritmos de 'backpropagation' (pesos dos nós alterados com base no resultado produzido) resiliente, com e sem retrocesso dos pesos, respetivamente. Consistem numa heuristica para aprendizagem supervisada em redes neuronais artificiais feedforward. 
		

			- sag e slr -> Algoritmos que induzem o algoritmo globalmente convergente (grprop). Estes são baseados nos algoritmos de 'backpropagation' resiliente, com a variante que modificam a componente da taxa de aprendizagem (associada com o gradiente absoluto mais baixo ou com a taxa de aprendizagem mais baixa, respetivamente).  


		<Nodos Intermédios>

			Diferentes estruturas de redes neuronais alcançam diferentes resultados, tanto em erro, como em tempo de execução. Assim, uma rede neuronal com mais neurónios do que outra pode chegar ao resultado esperado em menos tempo, mas esse resultado pode não estar de acordo com o esperado. Com o objetivo de testar as diferentes constituições de redes neuronais e o seu impacto sobre o output, são testadas diversas configurações dos nodos que as constituem:

				(10) -> 10 nodos intermédios numa só camada.

				(20, 10) -> 30 nodos intermédios divididos por duas camadas.

				(40, 20) -> 60 nodos intermédios divididos por duas camadas.


			O resultado que se espera obter com a rede neuronal de (40,20) nodos intermédios pensa-se ser aceitável (tendo em conta as diferentes variáveis de input), pelo que aumentar ainda mais a complexidade da rede neuronal não seria vantajoso. Da mesma forma, a rede neuronal de apenas 10 nodos intermédios crê-se ser insuficiente para satisfazer o objetivo, e é testada por motivos puramente académicos. 


		<Diferentes tamanhos e ordenações de input de treino>

			O tamanho do dataset utilizado para treinar a rede influência os resultados que esta alcançará no momento de a testar. Teóricamente, quanto maior e mais diversificado for o dataset, mais consistente será a rede neuronal, e melhor responderá aos testes efetuados. Assim, dado que o dataset fornecido possui apenas cerca de 800 registos, este é dividido entre datasets de treino e teste de rede, com diferentes tamanhos. A ordem pela qual estes testes participam no treino da rede neuronal afeta também o resultado final e os cálculos efetuados por esta, pelo que são testadas diferentes ordenações de datasets de treino (datasets original e invertido). 


		Procede-se então à análise dos resultados obtidos com as diversas configurações que é possível obter com a variação dos componentes descritos.

		<Testes realizados>
			O treino das redes neuronais e testes é efetuado recorrendo à linguagem R, suportada pela plataforma 'R Studio' e pela biblioteca 'neuralnet'. Como métricas para análise de resultados, são análisados o erro produzido no treino das redes, assim como o "Root Mean Square Error (rmse)" e "Percent BIAS (PBIAS)", sendo estes últimos suportados pela biblioteca "hydroGOF", e que permitem analisar de forma analítica a diferença média entre os resultados obtidos nos testes efetuados e os resultados esperados, e a tendência média que os resultados possuem comparativamente ao esperado (valores mais elevados ou mais baixos).   

			<Análise de resultados>
				

			<Conclusões>



	<Análise de variáveis relevantes>
		
		<Lógica>
			Apesar de que os registos fornecidos apresentam 9 variáveis que caracterizam o nível de fadiga, é possível que nem todas as váriaveis possuam o mesmo peso na decisão do output final, e então, podem ser prescíndiveis, não apenas simplificando os cálculos da rede em causa, mas melhorando o treino e o output gerado pelos testes. A medição de biométricas comportamentais possui diversas variantes cuja relevância deve ser estudada. Neste sentido, é então estudado o peso que as variáveis possuem, e são comparados os resultados obtidos anteriormente com os registos originais relativamente aos resultados obtidos com os registos mais relevantes.

		<Ferramenta WEKA>
			Inicialmente foi realizada uma abordagem que consistia na utilização de bibliotecas R, que permitem a análise do peso que as diferentes variáveis possuem sobre a estimativa do valor da variável de output numa rede neuronal artificial. No entanto, esta abordagem é limitada e produz resultados inconsistentes. Neste sentido, é dado uso a uma nova ferramenta de estudo de dados denominada 'Weka', que possui um conjunto de algoritmos de 'machine learning' que permitem a execução de tarefas de 'data mining'. Mais específicamente, são exploradas as suas capacidades de processamento de dados, que nos permitem classificar as variáveis de maior peso na determinação de um dado output, evitando assim a maçadora tarefa de 'tentativa e erro' (testar as diversas combinações de variáveis que produzem o melhor resultado). 

			
			<Resultados obtidos>
				Com o íntuito de avaliar então o mérito que cada variável possui na determinação da fadiga, seleciona-se o atributo 'FatigueLevel' como variável de output a analisar, e obtêm-se os seguintes resultados:

			<Comparação de resultados>
				De forma a avaliar o impacto que o novo conjunto de variáveis possui relativamente ao conjunto original, são testadas as redes cuja configuração obteve melhor resultado nos testes realizados anteriormente, mas agora com o novo conjunto, e comparam-se os valores obtidos, tirando-se seguintes conclusões:




				<Conclusões>