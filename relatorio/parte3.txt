<Otimização de escala de identificação de fadiga>
	Um dos desafios propostos consiste em encontrar a melhor escala de identificação de fadiga possível, e então, uma escala tal que não apenas diminua o erro dado pelas métricas usadas (p.e. rmse), mas que proporcione resultados mais consistentes quando é efetuado o treino e teste da rede neuronal.
	Para este efeito é explorada uma técnica muito comum no domínio de Machine Learning denominada "Clustering". Clustering consiste no agrupamento de registos de dados ou objetos de tal forma que objetos no mesmo grupo (ou cluster) sejam mais similares entre sí do que com elementos de outros clusters.

	Número ótimo de clusters

		Uma breve análise ao dataset original permite retirar alguns factos relevantes sobre os dados fornecidos:

		FatigueLevel       
		Min.   :1.000000  
		1st Qu.:2.000000  
		Median :2.000000  
		Mean   :2.484597  
		3rd Qu.:3.000000 
		Max.   :6.000000

		Número de registos por nível de fadiga:

  		1 - 184
  		2 - 257
  		3 - 247
  		4 - 126
  		5 - 26 
  		6 - 4


		- Apesar do nível de fatiga estar atualmente dividido em 7 níveis, o maior nível observado é o nível 6.
		- A média e a mediana são relativamente baixas, o que indica um elevado número de registos nos quais é possível afirmar que não existe fadiga.
		- Mais de 50% dos registos encontram-se nos níveis 2 e 3.

		Tendo em conta estas afirmações assim como os erros obtidos durante as fase de treino e teste da rede neuronal, é possível pressupor que o número de clusters poderá ser otimizado e assim os registos distribuídos pela nova escala de fadiga.

	
	Cálculo de número de clusters
		Uma abordagem a seguir no cálculo do número de clusters a utilizar seria remover o nível 7 do dataset original e distribuir os registos por 3 novos clusters. Estes clusters corresponderiam então a pares de níveis de fadiga, e permitiriam aumentar a concentração e existência de registos em cada um, assim como reduzir enormemente o erro obtido nos testes. No entanto, esta abordagem baseia-se em suposições, e para evitar a utilização do método de "tentativa e erro", são utilizadas primitivas que permitem obter o resultado esperado analiticamente.

		K-means clustering

			K-mean é um método de clustering comum que consiste na associação de registos com registos similares. Inicialmente escolhem-se k registos aleatoriamente que servem de centróides iniciais. Assim, a cada iteração associa-se um destes registos ao centróide mais próximo (similar), e recalculam-se os centróides (o centróide consiste na média dos valores associados). No final todos os registos estão contidos num dos k-clusters. Uma das vantagens deste método é que um registo pode não estar permanentemente associado a um dado cluster, podendo mudar de cluster se isso melhorar a solução.

			Em R existe a possibilidade de usar a função "kmeans" que permite aplicar o algoritmo referido a um dado dataset. No entanto, esta função deve também receber como parâmetro o número de clusters a formar, pelo que de forma a evitar um número elevado de testes de "tentativa e erro" torna-se necessário averiguar a quantidade de clusters que proporcionará uma melhor solução.

			Após uma aprofundada pesquisa, foi encontrada uma biblioteca que possui vários métodos de clustering e cluster validation, denominada "fpc".Em particular, esta biblioteca possui uma função denominada "pamk", capaz de estimar o número de clusters ótimo baseando-se em primitivas de k-means clustering (basicamente efetua a tentativa e erro).

------------			Assim, dado um intervalo aceitável de número de clusters, é utilizada uma função denominada wssplot que através de sucessivas utilizações da função kmeans, gera um gráfico representativo do número apropriado de clusters relativos ao dataset:

				<meter clusters1>

			O decréscimo na curva da função indica a tendência que estes dados possuem em formarem 3 grupos de registos com semelhanças. Assim, o output reforça a teoria de que o número de clusters mais adequando é formado por 3 clusters. Através da função pamk podemos reforçar esta teoria, dado que o output indica também a preferência por 3 clusters.

				<meter clustplotR>

----------			Finalmente através da função kmeans podemos também atribuir aos registos o atributo numérico do cluster no qual estes se inserem e obter um novo dataset com o qual podemos reavaliar os testes realizados anteriormente. 

			Não obstante os resultados obtidos, estes foram validados com a utilização da ferramenta WEKA, cuja solução final consiste também na utilização de 3 clusters (o output total pode ser encontrado em anexo). 

			=== Model and evaluation on training set ===

				Clustered Instances
				
				0      116 ( 14%)
				1       84 ( 10%)
				2       35 (  4%)
				3      458 ( 54%)
				4      151 ( 18%)



		<Comparação e análise de resultados>
 			Os resultados obtidos anteriormente são agora revalidados de acordo com o novo conjunto de clustering, sendo considerada a existência de fadiga apenas no nível 3 (dado o baixo volume de registos originais com um nível de fadiga elevado). Analisando os resultados obtidos (presentes em anexo), podemos derivar as seguintes conclusões:

 			- Para todas as configurações, os resultados melhoraram imensamente, obtendo inclusive estimativas completamente corretas (rmse a 0). Estes testes forma repetidos de forma a assegurar a sua validade, e confirma a importância da divisão correta em grupos de um dado conjunto de registos.
 			- A estimação da presença ou ausência de fadiga produziu valores pouco corretos. Isto pode ser explicado por uma má classificação dos níveis nos quais se denota fadiga ou não.


 			<Conclusões>






<meter output de weka em anexo> 			