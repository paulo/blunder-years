<Introdução>
	<Breve explicação de biométricas comportamentais>
	<Breve explicação sobre redes neuronais e ambiente R>


In machine learning and cognitive science, artificial neural networks (ANNs) are a family of statistical learning models inspired by biological neural networks (the central nervous systems of animals, in particular the brain) and are used to estimate or approximate functions that can depend on a large number of inputs and are generally unknown. Artificial neural networks are generally presented as systems of interconnected "neurons" which send messages to each other. The connections have numeric weights that can be tuned based on experience, making neural nets adaptive to inputs and capable of learning.

For example, a neural network for handwriting recognition is defined by a set of input neurons which may be activated by the pixels of an input image. After being weighted and transformed by a function (determined by the network's designer), the activations of these neurons are then passed on to other neurons. This process is repeated until finally, an output neuron is activated. This determines which character was read.






















<Identificação de níveis de fadiga>
	Um dos objetivos principais a alcançar consiste no treino e teste de uma rede neuronal artificial, tornando-a capaz de estimar o nível de fadiga partindo de input que consiste nas diversas variáveis biométricas fornecidas. Assim, é possível em R, através da plataforma "R Studio" e da biblioteca "neuralnet", criar uma rede neuronal, fornecer-lhe input e testar diferentes configurações de forma a comparar os resultados de cada uma. Neste sentido, é feita a análise do impacto que os diferentes componentes e variantes que constituem o treino de uma rede neuronal possuem sobre o resultado final.

	<Treino da rede>

		<Algoritmos>

		Existem diversos algoritmos que definem a forma como a rede neuronal "aprende", isto é, a forma como os seus diferentes nodos interagem e como variam os pesos destes. Estes algoritmos possuem um impacto no resultado final


		<acabar aqui>
		’rprop+’, -> ’rprop+’ and ’rprop-’ refer to the resilient backpropagation with and without weight backtracking
		’sag’, or ’slr’. -> ’sag’ and ’slr’ induce the usage of the modified globally convergent algorithm (grprop). 



		<Nodos Intermédios>

		Diferentes estruturas de redes neuronais alcançam diferentes resultados, tanto em erro, como em tempo de execução. Assim, uma rede neuronal com mais neurónios do que outra pode chegar ao resultado esperado em menos tempo, mas esse resultado pode não estar de acordo com o esperado. Com o objetivo de testar as diferentes constituições de redes neuronais e o seu impacto sobre o output, são testadas diversas configurações dos nodos que as constituem:

		(10) -> 10 nodos intermédios numa só camada.

		(20, 10) -> 30 nodos intermédios divididos por duas camadas.

		(40, 20) -> 60 nodos intermédios divididos por duas camadas.


		O resultado que se espera obter com a rede neuronal de 60 nodos intermédios pensa-se ser aceitável (tendo em conta as diferentes variáveis de input), pelo que aumentar ainda mais a complexidade da rede neuronal não seria vantajoso. Da mesma forma, a rede neuronal de apenas 10 nodos intermédio crê-se ser insuficiente para satisfazer o objetivo, e é testada por motivos puramente académicos. 



		<Diferentes tamanhos e ordenações de input de treino>

		O tamanho do dataset utilizado para treinar a rede influencia os resultados que esta alcançará no momento de a testar. Teóricamente, quanto maior e mais diversificado for o dataset, mais consistente será a rede neuronal, e melhor responderá aos testes efetuados. Assim, dado que o dataset fornecido possui apenas cerca de 800 registos, este é dividido entre datasets de treino e teste de rede, com diferentes tamanhos. A ordem pela qual estes testes participam no treino da rede neuronal afeta também o resultado final e os cálculos efetuados por esta, pelo que são testadas diferentes ordenações de datasets de treino (datasets original e invertido). 


		Procede-se então à análise dos resultados obtidos com as diversas configurações que é possível obter com a variação dos componentes descritos.


		<Testes realizados>
			<Diferentes métricas>
			<Análise de resultados>
	<Análise de variáveis relevantes>
		<Lógica>
		Apesar de que os registos fornecidos apresentam 9 variáveis que caracterizam o nível de fadiga, é possível que nem todas as váriaveis possuam o mesmo peso na decisão do output final, e então, podem ser prescíndiveis, não apenas simplificando os cálculos da rede em causa, mas melhorando o treino e o output gerado pelos testes. A medição de biométricas comportamentais possui diversas variantes que cuja relevância deve ser estudada. Neste sentido, é então estudado o peso que as variáveis possuem, e são comparados os resultados obtidos anteriormente realizados com os registos originais relativamente aos registos cujas variáveis consideradas menos relevantes são omitidas.



		<Comparação de resultados>
		<Explicação>















































<Identificação de existência ou ausência de fadiga>
	<Lógica e trabalho realizado>
		Com o intuíto de identificar a existência ou ausência de fadiga dado um determinado input, são feitas algumas considerações acerca dos níveis de fadiga mental apresentados. Através da análise da descrição de cada nível, é possivel extrair 2 grupos de estados mentais. O 1ºgrupo refere-se a estados onde um dado índividuo tem ainda a capacidade de funcionar e raciocinar dentro da normalidade, e é constituido pelos estados de 1 a 3 (inclusive). Quando um dado output estiver entre estes valores, considera-se a ausência de fadiga. De forma análoga, o 2ºgrupo refere-se a estados nos quais o índividuo perdeu certa capacidade de concentração e apresenta sinais de cansaço, e é constituido pelos estados de 4 a 7. Quando um dado output estiver entre estes valores, considera-se a existência de fadiga. Para facilitar a compreensão, os valores dos datasets foram normalizados para apresentar respostas lógicas, e então, testes cujo resultado pertença ao 1ºgrupo apresentarão um output de 0, e testes cujo resultado pertença ao 2ºgrupo apresentarão um output de 1.  

	<Apresentação de resultados>





























































<Otimização de escala de identificação de fadiga>
	Um dos desafios propostos consiste em encontrar a melhor escala de identificação de fadiga possível, e então, uma escala tal que não apenas diminua o erro dado pelas métricas usadas (p.e. rmse), mas que proporcione resultados mais consistentes quando é efetuado o treino e teste da rede neuronal.
	Para este efeito é explorada uma técnica muito comum no domínio de Machine Learning denominada "Clustering". Clustering consiste em agrupo registos de dados ou objetos de tal forma que objetos no mesmo grupo (ou cluster) sejam mais similares entre sí do que com elementos de outros clusters.

	Número ótimo de clusters

		Uma breve análise ao dataset original permite retirar alguns factos relevantes sobre os dados fornecidos:

		FatigueLevel       
		Min.   :1.000000  
		1st Qu.:2.000000  
		Median :2.000000  
		Mean   :2.484597  
		3rd Qu.:3.000000 
		Max.   :6.000000

  		1 - 184
  		2 - 257
  		3 - 247
  		4 - 126
  		5 - 26 
  		6 - 4


		- Apesar do nível de fatiga estar atualmente dividido em 7 níveis, o maior nível observado é o nível 6.
		- A média e a mediana são relativamente baixas, o que indica um elevado número de registos nos quais é possível afirmar que não existe fadiga.
		- Mais de 50% dos registos encontram-se nos níveis 2 e 3.

<a confirmar>
		Tendo em conta estas afirmações assim como os erros obtido durante as fase de treino e teste da rede neuronal, é possível pressupor que o número de clusters poderá ser otimizado e assim os registos distribuídos pela nova escala de fadiga.

	
	Cálculo de número de clusters
		Uma abordagem a seguir no cálculo do número de clusters a utilizar seria remover o nível 7 do dataset original e distribuir os registos por 3 novos clusters. Estes clusters corresponderiam então a pares de níveis de fadiga, e permitiriam aumentar a concentração e existência de registos em cada um, assim como reduzir enormemente o erro obtido nos testes. No entanto, esta abordagem basear-se em suposições, e para evitar a utilização do método de "tentativa e erro", são utilizadas primitivas que permitem obter o resultado esperado analiticamente.

		K-means clustering

		K-mean é um método de clustering comum que consiste na associação de registos com registos mais similares. Inicialmente escolhem-se k registos aleatoriamente que servem de centróides iniciais. Assim, a cada iteração associa-se um destes registos ao centróide mais próximo (similar), e recalculam-se os centróides (o centróide consiste na média dos valores associados). No final todos os registos estão contidos num dos k-clusters.
		Uma das vantagens deste método é que um registo pode não estar permanentemente associado a um dado cluster, podendo mudar de cluster se isso melhorar a solução.

		Em R existe a possibilidade de usar a função "kmeans" que permite aplicar o algoritmo referido a um dado dataset. No entanto, esta função deve também receber como parâmetro o número de clusters a formar, pelo que de forma a evitar um número elevado de testes de "tentativa e erro" torna-se necessário averiguar a quantidade de clusters que proporcionará uma melhor solução.

		Após uma profunda pesquisa, foi encontrada uma biblioteca que possui vários métodos de clustering e cluster validation, denominada "fpc". Em particular, esta biblioteca possui uma função denominada "pamk", capaz de estimar o número de clusters ótimo baseando-se em primitivas de k-means clustering (basicamente efetua a tentativa e erro).

		Assim, dado um intervalo aceitável de número de clusters:

		<meter output de função>

		O output reforça a teoria de que o número de clusters mais adequando é formado por 3 clusters. É possível agora observar que 

		<falta falar dos restantes gráficos>
		<falta utilizar a função kmeans>
		<falta fazer a análise de resultados>


	<Comparação e análise de resultados>























<Conclusões e Sugestões>














































<Resumo>

O presente documento consiste num relatório de análise à utilização de sistemas sub-simbólicos na representação de conhecimento e no desenvolvimento de mecanismos de raciocínio, nomeadamente Redes Neuronais Artificiais, para a resolução de problemas no domínio da análise de biométricas comportamentais e a sua importância na identificação e classificação de fadiga física e/ou mental. Na fase inicial do relatório são apresentados e analisados os diferentes dados obtidos durante o treino e teste das redes neuronais, assim como as diversas configurações de nodos intermédios, algoritmos de aprendizagem e tamanhos de input. É também realizada uma análise à relevância das variáveis sob as quais a rede depende e opera, sendo comparados os resultados obtidos com o conjunto de variáveis inicial e com o conjunto de variáveis presumidas relevantes.
Após configurada a rede, é efetuada sobre esta diferentes testes com o íntuito de avaliar os resultados num intervalo de resposta lógico, identificando-se a existência ou ausência de fadiga para um dado input.
Finalmente, são realizadas diversas tentativas de clustering de forma a encontrar uma escala de fadiga adequada ao problema e aos dados em causa, que diminua a percentagem de erro entre os resultados obtidos e os resultados reais nos testes efetuados à rede neuronal. 
A trabalho é desenvolvido sob a plataforma "R Studio", que permite facilmente a utilização da linguagem R para análise de datasets e a inclusão de diversas bibliotecas que enriquecem a forma como os dados são apresentados e obtidos.
O relatório termina com a apresentação dos resultados gerais obtidos e conclusões retiradas, sendo abordados os problemas que emergiram durante o desenvolvimento 





